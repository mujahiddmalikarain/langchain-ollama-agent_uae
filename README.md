# ğŸ§  LangChain + Ollama + FastAPI Backend

This backend service powers an intelligent assistant using:

- **LangChain** for LLM-driven reasoning
- **Ollama** to serve the LLaMA3 model locally
- **FastAPI** as the backend REST API
- **ChromaDB** + HuggingFace embeddings for Retrieval-Augmented Generation (RAG)
- **Custom Tools** (Weather, Developer Info)

---

## ğŸ“¦ Features

- ğŸ”— LangChain Agent with multiple tools
- ğŸŒ¤ï¸ WeatherTool for real-time weather-based suggestions
- ğŸ“š RAG integration using Chroma vector store
- ğŸš€ FastAPI endpoint to query the agent
- ğŸ§  Ollama running LLaMA3 locally as LLM
- ğŸ“Š Static + real-time data used in agent context

---

## ğŸ“ Folder Structure


---

## âš™ï¸ Requirements

- Python 3.10+
- Ollama installed with `llama3` model
- ChromaDB
- FastAPI
- Optional: MongoDB (for raw data storage)

Install dependencies:

```bash
pip install -r requirements.txt
